{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bbe16fc",
   "metadata": {},
   "source": [
    "# VO Pipeline\n",
    "Vision Algorithms for Mobile Robotics | Fall 2025 <br>\n",
    "David Jensen, Alessandro Pirini, Matteo Rubini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c5494",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5787b350",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b18998a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import cv2\n",
    "import skimage\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839c4c9",
   "metadata": {},
   "source": [
    "### Data\n",
    "_Ensure that all datasets have been downloaded and unzipped into their respective folders_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fa422c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset paths\n",
    "# (Set these variables before running)\n",
    "kitti_path = \"kitti/kitti05/kitti\"\n",
    "malaga_path = \"malaga/malaga-urban-dataset-extract-07\"\n",
    "parking_path = \"parking/parking\"\n",
    "# own_dataset_path = \"/path/to/own_dataset\"\n",
    "\n",
    "if DATASET == 0:\n",
    "    assert 'kitti_path' in locals(), \"You must define kitti_path\"\n",
    "    img_dir = os.path.join(kitti_path, '05/image_0')\n",
    "    images = glob(os.path.join(img_dir, '*.png'))\n",
    "    last_frame = 4540\n",
    "    K = np.array([\n",
    "        [7.18856e+02, 0, 6.071928e+02],\n",
    "        [0, 7.18856e+02, 1.852157e+02],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "    ground_truth = np.loadtxt(os.path.join(kitti_path, 'poses', '05.txt'))\n",
    "    ground_truth = ground_truth[:, [-9, -1]]  # same as MATLAB(:, [end-8 end])\n",
    "elif DATASET == 1:\n",
    "    assert 'malaga_path' in locals(), \"You must define malaga_path\"\n",
    "    img_dir = os.path.join(malaga_path, 'malaga-urban-dataset-extract-07_rectified_800x600_Images')\n",
    "    images = sorted(glob(os.path.join(img_dir, '*.png')))\n",
    "    last_frame = len(images)\n",
    "    K = np.array([\n",
    "        [621.18428, 0, 404.0076],\n",
    "        [0, 621.18428, 309.05989],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "elif DATASET == 2:\n",
    "    assert 'parking_path' in locals(), \"You must define parking_path\"\n",
    "    img_dir = os.path.join(kitti_path, '05/image_0')\n",
    "    images = glob(os.path.join(img_dir, '*.png'))\n",
    "    last_frame = 598\n",
    "    K = np.loadtxt(os.path.join(parking_path, 'K.txt'), delimiter=\",\", usecols=(0, 1, 2))\n",
    "    ground_truth = np.loadtxt(os.path.join(parking_path, 'poses.txt'))\n",
    "    ground_truth = ground_truth[:, [-9, -1]]\n",
    "elif DATASET == 3:\n",
    "    # Own Dataset\n",
    "    # TODO: define your own dataset and load K obtained from calibration of own camera\n",
    "    assert 'own_dataset_path' in locals(), \"You must define own_dataset_path\"\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0cdc90",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe4c0a3",
   "metadata": {},
   "source": [
    "### Paramaters for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cf3ebdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset -> 0: KITTI, 1: Malaga, 2: Parking, 3: Own Dataset\n",
    "DATASET = 0\n",
    "\n",
    "# Next keyframe to use for bootstrapping\n",
    "KITTI_BS_KF = 5\n",
    "MALAGA_BS_KF = 5\n",
    "PARKING_BS_KF = 5\n",
    "CUSTOM_BS_KF = 5\n",
    "\n",
    "# Number of rows and columns to divide image into for feature detection and number of features to track in each cell\n",
    "KITTI_ST_ROWS, KITTI_ST_COLS, KITTI_NUM_FEATURES = 2, 4, 20\n",
    "MALAGA_ST_ROWS, MALAGA_ST_COLS, MALAGA_NUM_FEATURES = 2, 4, 20\n",
    "PARKING_ST_ROWS, PARKING_ST_COLS, PARKING_NUM_FEATURES = 2, 4, 20\n",
    "CUSTOM_ST_ROWS, CUSTOM_ST_COLS, CUSTOM_NUM_FEATURES = 2, 4, 20\n",
    "\n",
    "# Paramaters for Shi-Tomasi corners\n",
    "feature_params = dict( maxCorners = 10,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "# Parameters for LKT\n",
    "lk_params = dict( winSize  = (15, 15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b09283",
   "metadata": {},
   "source": [
    "### Set parameters for specific datasets\n",
    "_Updates all parameters based on dataset being used_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63624629",
   "metadata": {},
   "source": [
    "#### Generate masks for feature tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc4c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_masks(img_path, rows, cols) -> list[np.ndarray]:\n",
    "    # get image shape\n",
    "    img = cv2.imread(img_path)\n",
    "    H, W = img.shape[:2]\n",
    "\n",
    "    # get boundries of the cells\n",
    "    row_boundries = np.linspace(0, H, rows + 1, dtype=int)\n",
    "    col_boundries = np.linspace(0, W, cols + 1, dtype=int)\n",
    "\n",
    "    # create masks left to right, top to bottom\n",
    "    masks = []\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            mask = np.zeros((H, W), dtype=\"uint8\")\n",
    "            r_s, r_e = row_boundries[[row, row + 1]]\n",
    "            c_s, c_e = col_boundries[[col, col + 1]]\n",
    "            mask[r_s:r_e, c_s:c_e] = 255\n",
    "            masks.append(mask)\n",
    "            \n",
    "            # visulaization\n",
    "            # vis = np.zeros_like(img)\n",
    "            # vis[mask] = img[mask]\n",
    "            # cv2.imshow(\"masked\", vis)\n",
    "            # cv2.waitKey(0)\n",
    "            # cv2.destroyAllWindows()\n",
    "\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1736dfd9",
   "metadata": {},
   "source": [
    "#### Paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e148f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_kf_1: str # path to first keyframe used for bootstrapping dataset\n",
    "bs_kf_2: str # path to second keyframe used for bootstrapping dataset\n",
    "feature_masks: list[np.ndarray] # mask image into regions for feature tracking \n",
    "\n",
    "if DATASET == 0:\n",
    "    assert 'kitti_path' in locals(), \"You must define kitti_path\"\n",
    "    bs_kf_1 = images[0]\n",
    "    bs_kf_2 = images[KITTI_BS_KF]\n",
    "    feature_masks = get_feature_masks(bs_kf_1, KITTI_ST_ROWS, KITTI_ST_COLS)\n",
    "\n",
    "elif DATASET == 1:\n",
    "    assert 'malaga_path' in locals(), \"You must define malaga_path\"\n",
    "    bs_kf_1 = images[0]\n",
    "    bs_kf_2 = images[MALAGA_BS_KF]\n",
    "    feature_masks = get_feature_masks(bs_kf_1, MALAGA_ST_ROWS, MALAGA_ST_COLS)\n",
    "\n",
    "elif DATASET == 2:\n",
    "    assert 'parking_path' in locals(), \"You must define parking_path\"\n",
    "    img_dir = os.path.join(kitti_path, '05/image_0')\n",
    "    images = glob(os.path.join(img_dir, '*.png'))\n",
    "    bs_kf_1 = images[0]\n",
    "    bs_kf_2 = images[PARKING_BS_KF]\n",
    "    feature_masks = get_feature_masks(bs_kf_1, PARKING_ST_ROWS, PARKING_ST_COLS)\n",
    "\n",
    "elif DATASET == 3:\n",
    "    # Own Dataset\n",
    "    # TODO: define your own dataset and load K obtained from calibration of own camera\n",
    "    assert 'own_dataset_path' in locals(), \"You must define own_dataset_path\"\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a0dc41",
   "metadata": {},
   "source": [
    "# Initialization\n",
    "- Select two keyframes with large enough baseline\n",
    "- Use indirect (feature-based) or direct (KLT) method to establish keypoint corrispondences between frames\n",
    "- Estimate relative pose and triangulate points to bootstrap point cloud (5-pt RANSAC)\n",
    "- Initialize VO pipeline with inlier keypoints and their associated landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c861e643",
   "metadata": {},
   "source": [
    "### Corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6e4f96f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 3 features found for mask 5!\n",
      "Only 2 features found for mask 7!\n",
      "Only 6 features found for mask 8!\n"
     ]
    }
   ],
   "source": [
    "# read in images as greyscale\n",
    "img_bs_kf_1 = cv2.imread(bs_kf_1, 0)\n",
    "img_bs_kf_2 = cv2.imread(bs_kf_2, 0)\n",
    "\n",
    "# find features in the first keyframe\n",
    "st_corners_kf_1 = np.empty((0, 1, 2), dtype=np.float32)\n",
    "for n, mask in enumerate(feature_masks):\n",
    "    features = cv2.goodFeaturesToTrack(img_bs_kf_1, mask=mask, **feature_params)\n",
    "    if features.shape[0] < 10:\n",
    "        print(f\"Only {features.shape[0]} features found for mask {n+1}!\")\n",
    "    st_corners_kf_1 = np.vstack((st_corners_kf_1, features))\n",
    "\n",
    "# track features to second keyframe\n",
    "st_corners_kf_2, st, err = cv2.calcOpticalFlowPyrLK(img_bs_kf_1, img_bs_kf_2, st_corners_kf_1, None, **lk_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb197d59",
   "metadata": {},
   "source": [
    "### Keypoint corrsipondences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KLT here maybe using itermediate frames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f86f87",
   "metadata": {},
   "source": [
    "# Operation\n",
    "- Match keypoints in current image to existing landmarks\n",
    "    - Extract keypoints (Harris)\n",
    "    - Track (KLT)\n",
    "- Estimate pose\n",
    "    - Estimate pose and handle outliers (P3P plus RANSAC)\n",
    "- Add new landmarks as needed by triangulating new features\n",
    "    - Keep track of candidate landmarks\n",
    "        - Keypoint itself\n",
    "        - Observation when first seen\n",
    "        - Pose when first seen\n",
    "    - Only add when they have been tracked for long enough and baselineis large enough\n",
    "    - Discard if track fails\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
